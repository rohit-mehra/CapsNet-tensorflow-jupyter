{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Simplest Capsule Implementation Based on my understanding of the Paper: https://arxiv.org/abs/1710.09829\n",
    "Referred to clear Doubts: https://github.com/naturomics/CapsNet-Tensorflow\n",
    "Tried to comment as much as possible, let me know if you find any error.\n",
    "Test Acc: 99.19 % # First round with default params of paper\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# set mnist data obj.\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True, reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already trained it for 54500 global steps\n",
    "ckpt = '../capsnet.ckpt' # Checkpoint file\n",
    "resume = True # True if you have the above file\n",
    "\n",
    "lr = 1e-4 # for 2nd round of training # first round was default 0.001\n",
    "\n",
    "train_round = 2\n",
    "do_test_first = True # do test eval\n",
    "save_after = 500 # and validate # checkpointing global step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Margin loss\n",
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lambda_val = 0.5  # down weight of the loss for absent digit classes\n",
    "epsilon = 1e-9\n",
    "\n",
    "batch_size = 128\n",
    "epoch = 3\n",
    "routing_iter = 3  # number of iterations in routing algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Squashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(in_tensor):\n",
    "    \"\"\"Squashing Function\n",
    "    Args:\n",
    "        (S) in_tensor: A 5-D input tensor of a capsule layer, shape [N, 1, J, next_D, 1],\n",
    "    Returns:\n",
    "        (V) out_tensor: A 5-D tensor with the same shape as input tensor of capsule layer but squashed in 3rd dimension.\n",
    "    \"\"\"\n",
    "    l2 = tf.norm(in_tensor, axis=-2, keep_dims=True,\n",
    "                 name='l2_per_vector_per_capsule_unit')  # [N, 1, J, 1, 1]\n",
    "    l2_square = tf.square(l2)\n",
    "    squash_factor = l2_square / (1 + l2_square)\n",
    "    return squash_factor * (in_tensor / l2)  # [N, 1, J, next_D, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Capsule Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Agreement\n",
    "def prediction_agreement(current_active_out, prediction):\n",
    "    # Tile current_active_out to get I=1152\n",
    "    V_J = tf.tile(current_active_out, multiples=[\n",
    "                  1, 1152, 1, 1, 1])  # [N, 1152, 10, 16, 1]\n",
    "    # [N, 1152, 10, 1, 16] x [N, 1152, 10, 16, 1] = [N, 1152, 10, 1, 1]\n",
    "    agreement = tf.matmul(prediction, V_J, transpose_a=True)\n",
    "    # Learning from samples aggregated # [1, 1152, 10, 1, 1]\n",
    "    agreement = tf.reduce_sum(agreement, axis=0, keep_dims=True)\n",
    "    return agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Routing Algorithm\n",
    "def routing(prediction, num_iters, prior_IJ):\n",
    "\n",
    "    with tf.variable_scope('routing'):\n",
    "        for r in range(int(num_iters)):\n",
    "            with tf.variable_scope('routing_iter_' + str(r)):\n",
    "                # Step 4:\n",
    "                c_IJ = tf.nn.softmax(prior_IJ, dim=2)  # [N, 1152, 10, 1, 1]\n",
    "                # Step 5:\n",
    "                weighted_unactive_out = tf.reduce_sum((c_IJ * prediction),\n",
    "                                                      axis=1,\n",
    "                                                      keep_dims=True)  # [N, 1, 10, 16, 1]\n",
    "                # Step 6:\n",
    "                current_active_out = squash(\n",
    "                    weighted_unactive_out)  # [N, 1, 10, 16, 1]\n",
    "                # Step 7:\n",
    "                prior_IJ += prediction_agreement(\n",
    "                    current_active_out, prediction)\n",
    "\n",
    "        return current_active_out  # [N, 1, 10, 16, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attribs of caps layer = W_IJ, prior_IJ, Conv2dunits\n",
    "# We Know I how to Know J?\n",
    "# Wij = [8 x 16]\n",
    "\n",
    "# I see this as information in 4D encoded ---> distributed represenation in 3D,\n",
    "# We can use it to flatten as well by setting next_capsules = 1, and next_D = vector dimension\n",
    "# Naive Flattening won't be required.\n",
    "def capsule_layer_prediction(in_tensor, num_iters=3, D=8, capsules=32, next_D=16, next_capsules=10, kernel_size=9, \n",
    "                             strides=2, name='caps_conv2d'):\n",
    "\n",
    "    batch_size = tf.shape(in_tensor)[0]\n",
    "    with tf.variable_scope(name):\n",
    "        # Optimized way from: https://github.com/naturomics/CapsNet-Tensorflow\n",
    "        capsule = tf.layers.conv2d(in_tensor,\n",
    "                                   capsules * D,\n",
    "                                   kernel_size,\n",
    "                                   strides,\n",
    "                                   kernel_initializer=tf.contrib.layers.xavier_initializer()) # NHWC*D # [N, 6, 6, 32*8]\n",
    "        # output of capsule units\n",
    "        # NID where I = C*H*W = [N, 1152, 1, 8, 1] <-- 1152[8, 1]\n",
    "        U_I = tf.reshape(capsule, shape=[batch_size, -1, 1, D, 1])\n",
    "        U_I = tf.tile(U_I, multiples=[1, 1, 10, 1, 1]) #  [N, 1152, 10, 8, 1]\n",
    "        U_I = squash(U_I) # Technically this is the end of primary capsules\n",
    "\n",
    "        capsule_shape = tf.shape(capsule)\n",
    "        I = 1152  # capsule_shape[1] # 1152 = 32 * 6 * 6 <-------- can be calculated dynamically\n",
    "        J = next_capsules  # 10\n",
    "\n",
    "        # W_IJ, shared weights\n",
    "        W_IJ = tf.Variable(tf.random_normal([1, I, J, D, next_D], stddev=0.03))  # [1, 1152, 10, 8, 16]\n",
    "        W_IJ = tf.tile(W_IJ, \n",
    "                       multiples=[batch_size, 1, 1, 1, 1]) # [N, 1152, 10, 8, 16] <-- IJ[8, 16]\n",
    "        \n",
    "        # prediction vectors, prediction u_j = [16D]\n",
    "        # [N, 1152, 10, 16, 8] x [N, 1152, 10, 8, 1] = [N, 1152, 10, 16, 1]\n",
    "        prediction_vectors = tf.matmul(W_IJ, U_I, transpose_a=True)\n",
    "    \n",
    "    with tf.variable_scope('routing'): # Not required\n",
    "        prior_IJ = tf.constant(np.zeros([1, I, J, 1, 1]), dtype=np.float32)  # nijkl\n",
    "        # NInext_D = [N, 1152, 10, 1, 1]\n",
    "        prior_IJ = tf.tile(prior_IJ, multiples=[batch_size, 1, 1, 1, 1])\n",
    "\n",
    "    activations = routing(prediction_vectors, num_iters, prior_IJ)\n",
    "\n",
    "    with tf.control_dependencies([activations]): # Sanity\n",
    "        return tf.squeeze(activations)  # [N, 10, 16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Network Arch:\n",
    "class CapsNet:\n",
    "    def __init__(self, inp_dim=28, num_iters=3, pred_vec_len=16, lr=1e-3, \n",
    "                 classes=10, m_plus=0.9, m_minus=0.1, lambda_val=0.5, scope=\"CapsNet\"):\n",
    "\n",
    "        print(\"Learning Rate={}, m_plus={}, m_minus={}, lambda_val={}\".format(lr, \n",
    "                                                                              m_plus,\n",
    "                                                                              m_minus,\n",
    "                                                                              lambda_val))\n",
    "\n",
    "        with tf.variable_scope(scope):\n",
    "            self.X = tf.placeholder(\n",
    "                tf.float32, shape=[None, inp_dim, inp_dim, 1], name='inputs')\n",
    "            self.Y = tf.placeholder(tf.float32, shape=[None, 10], name='one_hot_labels')\n",
    "\n",
    "            with tf.variable_scope('conv_layer'):\n",
    "                self.conv1 = tf.layers.conv2d(self.X,\n",
    "                                              filters=256,\n",
    "                                              kernel_size=9,\n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              activation=tf.nn.relu,\n",
    "                                              name='conv1')  # [N, 20, 20, 256]\n",
    "\n",
    "            # Capsule Layer Out\n",
    "            self.pred = tf.squeeze(capsule_layer_prediction(in_tensor=self.conv1, \n",
    "                                                            num_iters=num_iters, next_D=pred_vec_len),  # [N, 1, 10, 16, 1]\n",
    "                                   name='distributed_prediction')  # [N, 10, 16]\n",
    "\n",
    "            with tf.variable_scope('masking'):\n",
    "                self.masked_pred = tf.matmul(self.pred, tf.reshape(self.Y, shape=[-1, 10, 1]),\n",
    "                                             transpose_a=True, name='masked_pred')  # [N, 16, 10] x [N, 10, 1] = [N, 16, 1]\n",
    "                # [N, 10, 16] --> [N, 10]\n",
    "                self.pred_length = tf.sqrt(tf.reduce_sum(tf.square(self.pred) + 1e-9, axis=2, keep_dims=False))  \n",
    "\n",
    "            # [N, 10] * [N, 10] = [N, 10]\n",
    "            self.m_plus = self.Y * tf.square(tf.maximum(0., m_plus - self.pred_length)) # [N, 10]\n",
    "            self.m_minus = lambda_val * (1 - self.Y) * tf.square(tf.maximum(0., self.pred_length - m_minus))  # [N, 10]\n",
    "            self.margin_loss = tf.reduce_mean(tf.reduce_sum(self.m_plus + self.m_minus, axis=-1), name='margin_loss')\n",
    "\n",
    "            with tf.variable_scope('decoder'):\n",
    "                # [N, 16, 1] --> [N, 16]\n",
    "                decoder_inp = tf.reshape(self.masked_pred, \n",
    "                                         shape=[-1, pred_vec_len])\n",
    "                self.fc1 = tf.layers.dense(decoder_inp,\n",
    "                                           units=512,\n",
    "                                           activation=tf.nn.relu,\n",
    "                                           name='fc1')\n",
    "                self.fc2 = tf.layers.dense(self.fc1,\n",
    "                                           units=1024,\n",
    "                                           activation=tf.nn.relu,\n",
    "                                           name='fc2')\n",
    "\n",
    "                self.pred_X = tf.layers.dense(self.fc2,\n",
    "                                              units=inp_dim * inp_dim,\n",
    "                                              activation=tf.nn.sigmoid,\n",
    "                                              name='pred_X')  # [N, 28*28]\n",
    "\n",
    "                self.pred_image = tf.reshape(self.pred_X, shape=[-1, inp_dim, inp_dim, 1])\n",
    "            \n",
    "            # Backward\n",
    "            self.reconstruction_loss = tf.reduce_sum(tf.square(tf.reshape(self.X, shape=[-1, inp_dim * inp_dim]) - self.pred_X),\n",
    "                                                     name='reconstruction_loss')\n",
    "\n",
    "            self.loss = tf.add(self.margin_loss, 0.0005 * self.reconstruction_loss, name='loss')\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "            self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "            self.train_op = self.optimizer.minimize(self.loss, global_step=self.global_step)\n",
    "            \n",
    "            # function variables/ops:\n",
    "            # [N, 10] --> # [N,]\n",
    "            self.predictions = tf.squeeze(tf.argmax(self.pred_length, axis=1, output_type=tf.int32, name='predictions'))\n",
    "            # [N, 10] --> # [N,]\n",
    "            self.true = tf.squeeze(tf.argmax(self.Y, axis=1, output_type=tf.int32, name='true_values'))\n",
    "            \n",
    "            self.correct = tf.cast(tf.equal(self.true, self.predictions), dtype=tf.float32)\n",
    "            self.acc = tf.reduce_mean(self.correct) * 100\n",
    "\n",
    "            # meta variables:\n",
    "            self.tvars = tf.trainable_variables()\n",
    "\n",
    "    def predict(self, xs, get_recon_images=False, sess=None):\n",
    "        \"\"\"Returns Predicted Number and Reconstructed Image.\"\"\"\n",
    "        sess = sess or tf.get_default_session()\n",
    "        if get_recon_images:\n",
    "            return sess.run([self.predictions, self.pred_image], feed_dict={self.X: xs})\n",
    "        else:\n",
    "            return sess.run(self.predictions, feed_dict={self.X: xs})\n",
    "\n",
    "    def accuracy(self, xs, ys, sess=None):\n",
    "        \"\"\"Predicts and returns accuracy at current state.\"\"\"\n",
    "        sess = sess or tf.get_default_session()\n",
    "        return sess.run(self.acc, feed_dict={self.X: xs, self.Y: ys})\n",
    "\n",
    "    def learn(self, xs, ys, val_xs=None, val_ys=None, sess=None):\n",
    "        \"\"\"Train Step\"\"\"\n",
    "        sess = sess or tf.get_default_session()\n",
    "        \n",
    "        if val_xs is not None and val_ys is not None:\n",
    "            val_acc = self.accuracy(val_xs, val_ys, sess=sess)\n",
    "            return val_acc\n",
    "        else:\n",
    "            train_acc, loss, _ = sess.run([self.acc, self.loss, self.train_op], feed_dict={self.X: xs, self.Y: ys})\n",
    "            return train_acc, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate=0.0001, m_plus=0.9, m_minus=0.1, lambda_val=0.5\n",
      "Network Built..\n",
      "INFO:tensorflow:Restoring parameters from capsnet.ckpt\n",
      "RESUMED..\n",
      "1,98.800\n",
      "2,99.200\n",
      "3,99.600\n",
      "4,98.800\n",
      "5,99.200\n",
      "6,99.600\n",
      "7,98.800\n",
      "8,98.800\n",
      "9,99.600\n",
      "10,99.600\n",
      "11,99.600\n",
      "12,99.600\n",
      "13,98.000\n",
      "14,98.400\n",
      "15,99.600\n",
      "16,98.000\n",
      "17,100.000\n",
      "18,99.600\n",
      "19,99.600\n",
      "20,99.600\n",
      "21,99.600\n",
      "22,98.800\n",
      "23,99.600\n",
      "24,99.600\n",
      "25,98.800\n",
      "26,98.400\n",
      "27,99.200\n",
      "28,98.800\n",
      "29,100.000\n",
      "30,98.000\n",
      "31,99.200\n",
      "32,99.600\n",
      "33,99.600\n",
      "34,99.200\n",
      "35,99.600\n",
      "36,98.400\n",
      "37,98.400\n",
      "38,99.600\n",
      "39,100.000\n",
      "40,99.200\n",
      "Test Accuracy:  99.1900085449\n",
      "******************************************************************************************\n",
      "Training..learning_rate = 0.0001, total_epochs = 3\n",
      "1,100.000,0.167\n",
      "2,100.000,0.176\n",
      "3,100.000,0.156\n",
      "4,100.000,0.172\n",
      "5,100.000,0.164\n",
      "6,100.000,0.154\n",
      "7,100.000,0.175\n",
      "8,100.000,0.172\n",
      "9,100.000,0.165\n",
      "10,100.000,0.160\n",
      "11,100.000,0.174\n",
      "12,100.000,0.175\n",
      "13,100.000,0.157\n",
      "14,100.000,0.158\n",
      "15,100.000,0.150\n",
      "16,100.000,0.165\n",
      "17,100.000,0.179\n",
      "18,100.000,0.180\n",
      "19,100.000,0.157\n",
      "20,100.000,0.164\n",
      "21,100.000,0.154\n",
      "22,100.000,0.176\n",
      "23,100.000,0.142\n",
      "24,100.000,0.166\n",
      "25,100.000,0.163\n",
      "26,100.000,0.152\n",
      "27,100.000,0.161\n",
      "28,100.000,0.176\n",
      "29,100.000,0.161\n",
      "30,100.000,0.155\n",
      "31,100.000,0.159\n",
      "32,100.000,0.170\n",
      "33,100.000,0.172\n",
      "34,100.000,0.167\n",
      "35,100.000,0.162\n",
      "36,100.000,0.173\n",
      "37,100.000,0.152\n",
      "38,100.000,0.157\n",
      "39,100.000,0.162\n",
      "40,100.000,0.170\n",
      "41,100.000,0.164\n",
      "42,100.000,0.172\n",
      "43,100.000,0.163\n",
      "44,100.000,0.161\n",
      "45,100.000,0.160\n",
      "46,100.000,0.162\n",
      "47,100.000,0.162\n",
      "48,100.000,0.174\n",
      "49,100.000,0.161\n",
      "50,100.000,0.173\n",
      "51,100.000,0.165\n",
      "52,100.000,0.168\n",
      "53,100.000,0.172\n",
      "54,100.000,0.165\n",
      "55,100.000,0.159\n",
      "56,100.000,0.163\n",
      "57,100.000,0.156\n",
      "58,100.000,0.162\n",
      "59,100.000,0.166\n",
      "60,100.000,0.152\n",
      "61,100.000,0.173\n",
      "62,100.000,0.176\n",
      "63,100.000,0.165\n",
      "64,100.000,0.160\n",
      "65,100.000,0.157\n",
      "66,100.000,0.167\n",
      "67,100.000,0.158\n",
      "68,100.000,0.156\n",
      "69,100.000,0.155\n",
      "70,100.000,0.144\n",
      "71,100.000,0.163\n",
      "72,100.000,0.166\n",
      "73,100.000,0.157\n",
      "74,100.000,0.169\n",
      "75,100.000,0.150\n",
      "76,100.000,0.170\n",
      "77,100.000,0.177\n",
      "78,100.000,0.166\n",
      "79,100.000,0.169\n",
      "80,100.000,0.164\n",
      "81,100.000,0.176\n",
      "82,100.000,0.177\n",
      "83,100.000,0.164\n",
      "84,100.000,0.170\n",
      "85,100.000,0.149\n",
      "86,100.000,0.165\n",
      "87,100.000,0.173\n",
      "88,100.000,0.167\n",
      "89,100.000,0.180\n",
      "90,100.000,0.173\n",
      "91,100.000,0.158\n",
      "92,100.000,0.165\n",
      "93,100.000,0.170\n",
      "94,100.000,0.166\n",
      "95,100.000,0.169\n",
      "96,100.000,0.171\n",
      "97,100.000,0.143\n",
      "98,100.000,0.178\n",
      "99,100.000,0.172\n",
      "100,100.000,0.159\n",
      "101,100.000,0.158\n",
      "102,100.000,0.180\n",
      "103,100.000,0.169\n",
      "104,100.000,0.152\n",
      "105,100.000,0.165\n",
      "106,100.000,0.160\n",
      "107,100.000,0.163\n",
      "108,100.000,0.194\n",
      "109,100.000,0.172\n",
      "110,100.000,0.181\n",
      "111,100.000,0.166\n",
      "112,100.000,0.169\n",
      "113,100.000,0.153\n",
      "114,100.000,0.161\n",
      "115,100.000,0.159\n",
      "116,100.000,0.175\n",
      "117,100.000,0.160\n",
      "118,100.000,0.174\n",
      "119,100.000,0.166\n",
      "120,100.000,0.178\n",
      "121,100.000,0.173\n",
      "122,100.000,0.167\n",
      "123,100.000,0.172\n",
      "124,100.000,0.174\n",
      "125,100.000,0.165\n",
      "126,100.000,0.163\n",
      "127,100.000,0.170\n",
      "128,100.000,0.167\n",
      "129,100.000,0.159\n",
      "130,100.000,0.180\n",
      "131,100.000,0.174\n",
      "132,100.000,0.183\n",
      "133,100.000,0.163\n",
      "134,100.000,0.166\n",
      "135,100.000,0.170\n",
      "136,100.000,0.174\n",
      "137,100.000,0.177\n",
      "138,100.000,0.162\n",
      "139,100.000,0.170\n",
      "140,100.000,0.166\n",
      "141,100.000,0.167\n",
      "142,100.000,0.161\n",
      "143,100.000,0.149\n",
      "144,100.000,0.159\n",
      "145,100.000,0.172\n",
      "146,100.000,0.159\n",
      "147,100.000,0.159\n",
      "148,100.000,0.168\n",
      "149,100.000,0.183\n",
      "150,100.000,0.174\n",
      "151,100.000,0.167\n",
      "152,100.000,0.153\n",
      "153,100.000,0.156\n",
      "154,100.000,0.163\n",
      "155,100.000,0.177\n",
      "156,100.000,0.163\n",
      "157,100.000,0.184\n",
      "158,100.000,0.174\n",
      "159,100.000,0.162\n",
      "160,100.000,0.167\n",
      "161,100.000,0.151\n",
      "162,100.000,0.166\n",
      "163,100.000,0.185\n",
      "164,100.000,0.167\n",
      "165,100.000,0.177\n",
      "166,100.000,0.167\n",
      "167,100.000,0.153\n",
      "168,100.000,0.176\n",
      "169,100.000,0.174\n",
      "170,100.000,0.176\n",
      "171,100.000,0.167\n",
      "172,100.000,0.167\n",
      "173,100.000,0.159\n",
      "174,100.000,0.182\n",
      "175,100.000,0.154\n",
      "176,100.000,0.170\n",
      "177,100.000,0.185\n",
      "178,100.000,0.179\n",
      "179,100.000,0.182\n",
      "180,100.000,0.161\n",
      "181,100.000,0.165\n",
      "182,100.000,0.167\n",
      "183,100.000,0.163\n",
      "184,100.000,0.161\n",
      "185,100.000,0.167\n",
      "186,100.000,0.169\n",
      "187,100.000,0.159\n",
      "188,100.000,0.166\n",
      "189,100.000,0.158\n",
      "190,100.000,0.181\n",
      "191,100.000,0.166\n",
      "192,100.000,0.171\n",
      "193,100.000,0.168\n",
      "194,100.000,0.171\n",
      "195,100.000,0.169\n",
      "196,100.000,0.174\n",
      "197,100.000,0.149\n",
      "198,100.000,0.165\n",
      "199,100.000,0.163\n",
      "200,100.000,0.172\n",
      "201,100.000,0.163\n",
      "202,100.000,0.161\n",
      "203,100.000,0.175\n",
      "204,100.000,0.170\n",
      "205,100.000,0.153\n",
      "206,100.000,0.183\n",
      "207,100.000,0.164\n",
      "208,100.000,0.181\n",
      "209,100.000,0.170\n",
      "210,100.000,0.150\n",
      "211,100.000,0.161\n",
      "212,100.000,0.169\n",
      "213,100.000,0.167\n",
      "214,100.000,0.165\n",
      "215,100.000,0.173\n",
      "216,100.000,0.168\n",
      "217,100.000,0.154\n",
      "218,100.000,0.172\n",
      "219,100.000,0.172\n",
      "220,100.000,0.172\n",
      "221,100.000,0.149\n",
      "222,100.000,0.164\n",
      "223,100.000,0.171\n",
      "224,100.000,0.182\n",
      "225,100.000,0.175\n",
      "226,100.000,0.166\n",
      "227,100.000,0.144\n",
      "228,100.000,0.168\n",
      "229,100.000,0.167\n",
      "230,100.000,0.164\n",
      "231,100.000,0.176\n",
      "232,100.000,0.154\n",
      "233,100.000,0.161\n",
      "234,100.000,0.181\n",
      "235,99.219,0.174\n",
      "236,100.000,0.174\n",
      "237,100.000,0.162\n",
      "238,100.000,0.151\n",
      "239,100.000,0.173\n",
      "240,100.000,0.165\n",
      "241,100.000,0.158\n",
      "242,100.000,0.177\n",
      "243,100.000,0.150\n",
      "244,100.000,0.171\n",
      "245,100.000,0.172\n",
      "246,100.000,0.170\n",
      "247,100.000,0.176\n",
      "248,100.000,0.160\n",
      "249,100.000,0.182\n",
      "250,100.000,0.158\n",
      "251,100.000,0.185\n",
      "252,100.000,0.166\n",
      "253,100.000,0.163\n",
      "254,100.000,0.159\n",
      "255,100.000,0.168\n",
      "256,100.000,0.171\n",
      "257,100.000,0.169\n",
      "258,100.000,0.171\n",
      "259,100.000,0.176\n",
      "260,100.000,0.161\n",
      "261,100.000,0.172\n",
      "262,100.000,0.160\n",
      "263,100.000,0.170\n",
      "264,100.000,0.162\n",
      "265,100.000,0.159\n",
      "266,100.000,0.180\n",
      "267,100.000,0.144\n",
      "268,100.000,0.160\n",
      "269,100.000,0.176\n",
      "270,99.219,0.179\n",
      "271,100.000,0.171\n",
      "272,100.000,0.153\n",
      "273,100.000,0.180\n",
      "274,100.000,0.144\n",
      "275,100.000,0.170\n",
      "276,100.000,0.146\n",
      "277,100.000,0.171\n",
      "278,100.000,0.158\n",
      "279,100.000,0.168\n",
      "280,100.000,0.171\n",
      "281,100.000,0.179\n",
      "282,100.000,0.179\n",
      "283,100.000,0.163\n",
      "284,100.000,0.195\n",
      "285,100.000,0.170\n",
      "286,100.000,0.173\n",
      "287,100.000,0.164\n",
      "288,100.000,0.163\n",
      "289,100.000,0.160\n",
      "290,100.000,0.175\n",
      "291,100.000,0.171\n",
      "292,100.000,0.167\n",
      "293,100.000,0.170\n",
      "294,100.000,0.167\n",
      "295,100.000,0.171\n",
      "296,100.000,0.162\n",
      "297,100.000,0.161\n",
      "298,100.000,0.170\n",
      "299,100.000,0.179\n",
      "300,100.000,0.171\n",
      "301,100.000,0.161\n",
      "302,100.000,0.160\n",
      "303,100.000,0.156\n",
      "304,100.000,0.169\n",
      "305,100.000,0.173\n",
      "306,100.000,0.176\n",
      "307,100.000,0.157\n",
      "308,100.000,0.167\n",
      "309,100.000,0.181\n",
      "310,100.000,0.147\n",
      "311,100.000,0.163\n",
      "312,100.000,0.172\n",
      "313,100.000,0.170\n",
      "314,100.000,0.144\n",
      "315,100.000,0.180\n",
      "316,100.000,0.170\n",
      "317,100.000,0.155\n",
      "318,100.000,0.159\n",
      "319,100.000,0.162\n",
      "320,100.000,0.166\n",
      "321,100.000,0.190\n",
      "322,100.000,0.166\n",
      "323,100.000,0.171\n",
      "324,100.000,0.173\n",
      "325,100.000,0.162\n",
      "326,100.000,0.180\n",
      "327,100.000,0.170\n",
      "328,100.000,0.166\n",
      "329,100.000,0.172\n",
      "330,100.000,0.180\n",
      "331,100.000,0.160\n",
      "332,100.000,0.180\n",
      "333,100.000,0.171\n",
      "334,100.000,0.165\n",
      "335,100.000,0.172\n",
      "336,100.000,0.164\n",
      "337,100.000,0.171\n",
      "338,100.000,0.181\n",
      "339,100.000,0.172\n",
      "340,100.000,0.162\n",
      "341,100.000,0.180\n",
      "342,100.000,0.154\n",
      "343,100.000,0.158\n",
      "344,100.000,0.168\n",
      "345,100.000,0.158\n",
      "346,100.000,0.146\n",
      "347,100.000,0.183\n",
      "348,100.000,0.181\n",
      "349,100.000,0.164\n",
      "350,100.000,0.172\n",
      "351,100.000,0.165\n",
      "352,100.000,0.153\n",
      "353,100.000,0.193\n",
      "354,100.000,0.168\n",
      "355,100.000,0.164\n",
      "356,100.000,0.164\n",
      "357,100.000,0.170\n",
      "358,100.000,0.171\n",
      "359,100.000,0.159\n",
      "360,100.000,0.160\n",
      "361,100.000,0.162\n",
      "362,100.000,0.161\n",
      "363,100.000,0.167\n",
      "364,100.000,0.170\n",
      "365,100.000,0.166\n",
      "366,100.000,0.184\n",
      "367,100.000,0.166\n",
      "368,100.000,0.179\n",
      "369,100.000,0.164\n",
      "370,100.000,0.165\n",
      "371,100.000,0.157\n",
      "372,100.000,0.170\n",
      "373,100.000,0.163\n",
      "374,100.000,0.166\n",
      "375,100.000,0.163\n",
      "376,100.000,0.181\n",
      "377,100.000,0.162\n",
      "378,100.000,0.166\n",
      "379,100.000,0.176\n",
      "380,100.000,0.175\n",
      "381,100.000,0.180\n",
      "382,100.000,0.153\n",
      "383,100.000,0.171\n",
      "384,100.000,0.175\n",
      "385,100.000,0.178\n",
      "386,100.000,0.167\n",
      "387,100.000,0.170\n",
      "388,100.000,0.157\n",
      "389,100.000,0.172\n",
      "390,100.000,0.172\n",
      "391,100.000,0.166\n",
      "392,100.000,0.171\n",
      "393,100.000,0.157\n",
      "394,100.000,0.152\n",
      "395,100.000,0.159\n",
      "396,100.000,0.173\n",
      "397,100.000,0.151\n",
      "398,100.000,0.172\n",
      "399,100.000,0.168\n",
      "400,100.000,0.184\n",
      "401,100.000,0.153\n",
      "402,100.000,0.173\n",
      "403,100.000,0.162\n",
      "404,100.000,0.167\n",
      "405,100.000,0.165\n",
      "406,100.000,0.160\n",
      "407,100.000,0.147\n",
      "408,100.000,0.164\n",
      "409,100.000,0.185\n",
      "410,100.000,0.170\n",
      "411,100.000,0.162\n",
      "412,100.000,0.174\n",
      "413,100.000,0.156\n",
      "414,100.000,0.174\n",
      "415,100.000,0.174\n",
      "416,100.000,0.151\n",
      "417,100.000,0.163\n",
      "418,100.000,0.162\n",
      "419,100.000,0.154\n",
      "420,100.000,0.173\n",
      "421,100.000,0.171\n",
      "422,100.000,0.170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423,100.000,0.163\n",
      "424,100.000,0.165\n",
      "425,100.000,0.180\n",
      "426,100.000,0.177\n",
      "427,100.000,0.161\n",
      "428,100.000,0.159\n",
      "429,100.000,0.172\n",
      "430,100.000,0.171\n",
      "431,100.000,0.153\n",
      "432,100.000,0.176\n",
      "433,100.000,0.175\n",
      "434,100.000,0.166\n",
      "435,100.000,0.176\n",
      "436,100.000,0.169\n",
      "437,100.000,0.160\n",
      "438,100.000,0.151\n",
      "439,100.000,0.157\n",
      "440,100.000,0.162\n",
      "441,100.000,0.171\n",
      "442,100.000,0.169\n",
      "443,100.000,0.157\n",
      "444,100.000,0.180\n",
      "445,100.000,0.169\n",
      "446,100.000,0.168\n",
      "447,100.000,0.162\n",
      "448,100.000,0.173\n",
      "449,100.000,0.160\n",
      "450,100.000,0.157\n",
      "451,100.000,0.156\n",
      "452,100.000,0.163\n",
      "453,100.000,0.158\n",
      "454,100.000,0.154\n",
      "455,100.000,0.183\n",
      "456,100.000,0.175\n",
      "457,100.000,0.151\n",
      "458,100.000,0.160\n",
      "459,100.000,0.155\n",
      "460,100.000,0.176\n",
      "461,100.000,0.159\n",
      "462,100.000,0.156\n",
      "463,100.000,0.166\n",
      "464,100.000,0.171\n",
      "465,100.000,0.165\n",
      "466,100.000,0.169\n",
      "467,100.000,0.157\n",
      "468,100.000,0.155\n",
      "469,100.000,0.168\n",
      "470,100.000,0.163\n",
      "471,100.000,0.173\n",
      "472,100.000,0.162\n",
      "473,100.000,0.160\n",
      "474,100.000,0.170\n",
      "475,100.000,0.155\n",
      "476,100.000,0.161\n",
      "477,100.000,0.166\n",
      "478,100.000,0.171\n",
      "479,100.000,0.179\n",
      "480,100.000,0.150\n",
      "481,100.000,0.161\n",
      "482,100.000,0.173\n",
      "483,100.000,0.158\n",
      "484,100.000,0.180\n",
      "485,100.000,0.154\n",
      "486,100.000,0.168\n",
      "487,100.000,0.161\n",
      "488,100.000,0.156\n",
      "489,100.000,0.171\n",
      "490,100.000,0.176\n",
      "491,100.000,0.156\n",
      "492,100.000,0.178\n",
      "493,100.000,0.158\n",
      "494,100.000,0.157\n",
      "495,100.000,0.166\n",
      "496,100.000,0.173\n",
      "497,100.000,0.163\n",
      "498,100.000,0.175\n",
      "499,100.000,0.161\n",
      "SAVED..\n",
      "\n",
      "501,100.000,0.157\n",
      "502,100.000,0.163\n",
      "503,100.000,0.180\n",
      "504,100.000,0.159\n",
      "505,100.000,0.156\n",
      "506,100.000,0.167\n",
      "507,100.000,0.160\n",
      "508,100.000,0.164\n",
      "509,100.000,0.173\n",
      "510,100.000,0.169\n",
      "511,100.000,0.173\n",
      "512,100.000,0.163\n",
      "513,100.000,0.164\n",
      "514,100.000,0.162\n",
      "515,100.000,0.158\n",
      "516,100.000,0.163\n",
      "517,100.000,0.159\n",
      "518,100.000,0.168\n",
      "519,100.000,0.175\n",
      "520,100.000,0.171\n",
      "521,100.000,0.168\n",
      "522,100.000,0.168\n",
      "523,100.000,0.164\n",
      "524,100.000,0.176\n",
      "525,100.000,0.180\n",
      "526,100.000,0.161\n",
      "527,100.000,0.171\n",
      "528,100.000,0.164\n",
      "529,100.000,0.163\n",
      "530,100.000,0.165\n",
      "531,100.000,0.169\n",
      "532,100.000,0.175\n",
      "533,100.000,0.161\n",
      "534,100.000,0.182\n",
      "535,100.000,0.174\n",
      "536,100.000,0.173\n",
      "537,100.000,0.161\n",
      "538,100.000,0.159\n",
      "539,100.000,0.171\n",
      "540,100.000,0.180\n",
      "541,100.000,0.172\n",
      "542,100.000,0.159\n",
      "543,100.000,0.169\n",
      "544,100.000,0.159\n",
      "545,100.000,0.159\n",
      "546,100.000,0.157\n",
      "547,100.000,0.181\n",
      "548,100.000,0.176\n",
      "549,100.000,0.174\n",
      "550,100.000,0.174\n",
      "551,100.000,0.173\n",
      "552,100.000,0.157\n",
      "553,100.000,0.159\n",
      "554,100.000,0.155\n",
      "555,100.000,0.181\n",
      "556,100.000,0.168\n",
      "557,100.000,0.164\n",
      "558,100.000,0.173\n",
      "559,100.000,0.174\n",
      "560,100.000,0.151\n",
      "561,100.000,0.171\n",
      "562,100.000,0.157\n",
      "563,100.000,0.171\n",
      "564,100.000,0.160\n",
      "565,100.000,0.174\n",
      "566,100.000,0.170\n",
      "567,100.000,0.167\n",
      "568,100.000,0.167\n",
      "569,100.000,0.175\n",
      "570,100.000,0.154\n",
      "571,100.000,0.172\n",
      "572,100.000,0.165\n",
      "573,100.000,0.170\n",
      "574,100.000,0.156\n",
      "575,100.000,0.156\n",
      "576,100.000,0.167\n",
      "577,100.000,0.167\n",
      "578,100.000,0.154\n",
      "579,100.000,0.155\n",
      "580,100.000,0.148\n",
      "581,100.000,0.173\n",
      "582,100.000,0.168\n",
      "583,100.000,0.179\n",
      "584,100.000,0.163\n",
      "585,100.000,0.154\n",
      "586,100.000,0.149\n",
      "587,100.000,0.170\n",
      "588,100.000,0.143\n",
      "589,100.000,0.163\n",
      "590,100.000,0.165\n",
      "591,100.000,0.160\n",
      "592,100.000,0.167\n",
      "593,100.000,0.169\n",
      "594,100.000,0.163\n",
      "595,100.000,0.157\n",
      "596,100.000,0.145\n",
      "597,100.000,0.172\n",
      "598,100.000,0.172\n",
      "599,100.000,0.164\n",
      "600,100.000,0.160\n",
      "601,100.000,0.150\n",
      "602,100.000,0.159\n",
      "603,100.000,0.161\n",
      "604,100.000,0.170\n",
      "605,100.000,0.163\n",
      "606,100.000,0.172\n",
      "607,100.000,0.162\n",
      "608,100.000,0.171\n",
      "609,100.000,0.160\n",
      "610,100.000,0.161\n",
      "611,100.000,0.172\n",
      "612,100.000,0.160\n",
      "613,100.000,0.151\n",
      "614,100.000,0.167\n",
      "615,100.000,0.145\n",
      "616,100.000,0.160\n",
      "617,100.000,0.187\n",
      "618,100.000,0.159\n",
      "619,100.000,0.165\n",
      "620,100.000,0.164\n",
      "621,100.000,0.178\n",
      "622,100.000,0.166\n",
      "623,100.000,0.189\n",
      "624,100.000,0.160\n",
      "625,100.000,0.160\n",
      "626,100.000,0.160\n",
      "627,100.000,0.162\n",
      "628,100.000,0.164\n",
      "629,100.000,0.142\n",
      "630,100.000,0.165\n",
      "631,100.000,0.174\n",
      "632,100.000,0.165\n",
      "633,100.000,0.169\n",
      "634,100.000,0.184\n",
      "635,100.000,0.183\n",
      "636,100.000,0.160\n",
      "637,100.000,0.151\n",
      "638,100.000,0.170\n",
      "639,100.000,0.162\n",
      "640,100.000,0.162\n",
      "641,100.000,0.171\n",
      "642,100.000,0.159\n",
      "643,100.000,0.179\n",
      "644,100.000,0.166\n",
      "645,100.000,0.153\n",
      "646,100.000,0.169\n",
      "647,100.000,0.176\n",
      "648,100.000,0.163\n",
      "649,100.000,0.164\n",
      "650,100.000,0.177\n",
      "651,100.000,0.171\n",
      "652,100.000,0.161\n",
      "653,100.000,0.166\n",
      "654,100.000,0.174\n",
      "655,100.000,0.158\n",
      "656,100.000,0.159\n",
      "657,100.000,0.164\n",
      "658,100.000,0.154\n",
      "659,100.000,0.164\n",
      "660,100.000,0.179\n",
      "661,100.000,0.173\n",
      "662,100.000,0.160\n",
      "663,100.000,0.178\n",
      "664,100.000,0.163\n",
      "665,100.000,0.155\n",
      "666,100.000,0.183\n",
      "667,100.000,0.162\n",
      "668,100.000,0.175\n",
      "669,100.000,0.166\n",
      "670,100.000,0.163\n",
      "671,100.000,0.177\n",
      "672,99.219,0.179\n",
      "673,99.219,0.168\n",
      "674,100.000,0.172\n",
      "675,100.000,0.155\n",
      "676,100.000,0.165\n",
      "677,100.000,0.180\n",
      "678,100.000,0.157\n",
      "679,100.000,0.177\n",
      "680,100.000,0.165\n",
      "681,100.000,0.167\n",
      "682,100.000,0.168\n",
      "683,100.000,0.165\n",
      "684,100.000,0.159\n",
      "685,100.000,0.170\n",
      "686,100.000,0.176\n",
      "687,100.000,0.163\n",
      "688,100.000,0.172\n",
      "689,100.000,0.161\n",
      "690,100.000,0.174\n",
      "691,100.000,0.173\n",
      "692,100.000,0.177\n",
      "693,100.000,0.164\n",
      "694,100.000,0.166\n",
      "695,100.000,0.166\n",
      "696,100.000,0.182\n",
      "697,100.000,0.156\n",
      "698,100.000,0.179\n",
      "699,100.000,0.178\n",
      "700,100.000,0.171\n",
      "701,100.000,0.170\n",
      "702,100.000,0.179\n",
      "703,100.000,0.158\n",
      "704,100.000,0.165\n",
      "705,100.000,0.171\n",
      "706,100.000,0.155\n",
      "707,100.000,0.171\n",
      "708,100.000,0.153\n",
      "709,100.000,0.167\n",
      "710,100.000,0.187\n",
      "711,100.000,0.169\n",
      "712,100.000,0.170\n",
      "713,100.000,0.166\n",
      "714,100.000,0.162\n",
      "715,100.000,0.188\n",
      "716,100.000,0.165\n",
      "717,100.000,0.143\n",
      "718,100.000,0.160\n",
      "719,100.000,0.157\n",
      "720,100.000,0.171\n",
      "721,100.000,0.175\n",
      "722,100.000,0.169\n",
      "723,100.000,0.170\n",
      "724,100.000,0.167\n",
      "725,100.000,0.155\n",
      "726,100.000,0.183\n",
      "727,100.000,0.168\n",
      "728,100.000,0.168\n",
      "729,100.000,0.186\n",
      "730,100.000,0.164\n",
      "731,100.000,0.187\n",
      "732,100.000,0.165\n",
      "733,100.000,0.160\n",
      "734,100.000,0.176\n",
      "735,100.000,0.166\n",
      "736,100.000,0.167\n",
      "737,100.000,0.176\n",
      "738,100.000,0.168\n",
      "739,100.000,0.166\n",
      "740,100.000,0.164\n",
      "741,100.000,0.170\n",
      "742,99.219,0.184\n",
      "743,100.000,0.156\n",
      "744,100.000,0.170\n",
      "745,100.000,0.169\n",
      "746,100.000,0.162\n",
      "747,100.000,0.164\n",
      "748,100.000,0.179\n",
      "749,100.000,0.176\n",
      "750,100.000,0.159\n",
      "751,100.000,0.161\n",
      "752,100.000,0.175\n",
      "753,100.000,0.147\n",
      "754,100.000,0.179\n",
      "755,100.000,0.161\n",
      "756,100.000,0.168\n",
      "757,100.000,0.150\n",
      "758,100.000,0.173\n",
      "759,100.000,0.169\n",
      "760,100.000,0.180\n",
      "761,100.000,0.169\n",
      "762,100.000,0.152\n",
      "763,100.000,0.182\n",
      "764,100.000,0.165\n",
      "765,100.000,0.171\n",
      "766,100.000,0.171\n",
      "767,100.000,0.162\n",
      "768,100.000,0.165\n",
      "769,100.000,0.162\n",
      "770,100.000,0.162\n",
      "771,100.000,0.162\n",
      "772,100.000,0.168\n",
      "773,100.000,0.173\n",
      "774,100.000,0.152\n",
      "775,100.000,0.155\n",
      "776,100.000,0.165\n",
      "777,100.000,0.168\n",
      "778,100.000,0.161\n",
      "779,100.000,0.169\n",
      "780,100.000,0.158\n",
      "781,100.000,0.166\n",
      "782,100.000,0.157\n",
      "783,100.000,0.168\n",
      "784,100.000,0.164\n",
      "785,100.000,0.184\n",
      "786,100.000,0.174\n",
      "787,100.000,0.162\n",
      "788,100.000,0.163\n",
      "789,100.000,0.171\n",
      "790,99.219,0.162\n",
      "791,100.000,0.166\n",
      "792,100.000,0.148\n",
      "793,100.000,0.172\n",
      "794,100.000,0.174\n",
      "795,100.000,0.165\n",
      "796,100.000,0.183\n",
      "797,100.000,0.155\n",
      "798,100.000,0.180\n",
      "799,100.000,0.158\n",
      "800,100.000,0.164\n",
      "801,100.000,0.175\n",
      "802,100.000,0.171\n",
      "803,100.000,0.159\n",
      "804,100.000,0.173\n",
      "805,100.000,0.169\n",
      "806,100.000,0.162\n",
      "807,100.000,0.194\n",
      "808,100.000,0.176\n",
      "809,100.000,0.164\n",
      "810,100.000,0.157\n",
      "811,100.000,0.159\n",
      "812,100.000,0.154\n",
      "813,100.000,0.159\n",
      "814,100.000,0.170\n",
      "815,100.000,0.179\n",
      "816,100.000,0.164\n",
      "817,100.000,0.162\n",
      "818,100.000,0.167\n",
      "819,100.000,0.170\n",
      "820,100.000,0.175\n",
      "821,100.000,0.175\n",
      "822,100.000,0.181\n",
      "823,100.000,0.153\n",
      "824,100.000,0.172\n",
      "825,100.000,0.161\n",
      "826,100.000,0.179\n",
      "827,100.000,0.154\n",
      "828,100.000,0.156\n",
      "829,100.000,0.168\n",
      "830,100.000,0.159\n",
      "831,100.000,0.167\n",
      "832,100.000,0.172\n",
      "833,100.000,0.164\n",
      "834,100.000,0.155\n",
      "835,100.000,0.162\n",
      "836,100.000,0.173\n",
      "837,100.000,0.159\n",
      "838,100.000,0.187\n",
      "839,100.000,0.165\n",
      "840,100.000,0.173\n",
      "841,100.000,0.162\n",
      "842,100.000,0.170\n",
      "843,100.000,0.157\n",
      "844,100.000,0.170\n",
      "845,100.000,0.173\n",
      "846,100.000,0.177\n",
      "847,100.000,0.170\n",
      "848,100.000,0.165\n",
      "849,100.000,0.166\n",
      "850,100.000,0.175\n",
      "851,100.000,0.180\n",
      "852,100.000,0.178\n",
      "853,100.000,0.169\n",
      "854,100.000,0.162\n",
      "855,100.000,0.161\n",
      "856,100.000,0.171\n",
      "857,100.000,0.168\n",
      "858,100.000,0.152\n",
      "859,100.000,0.163\n",
      "860,100.000,0.162\n",
      "861,100.000,0.167\n",
      "862,100.000,0.151\n",
      "863,100.000,0.163\n",
      "864,100.000,0.162\n",
      "865,100.000,0.185\n",
      "866,100.000,0.164\n",
      "867,100.000,0.155\n",
      "868,100.000,0.165\n",
      "869,100.000,0.147\n",
      "870,100.000,0.175\n",
      "871,100.000,0.165\n",
      "872,100.000,0.159\n",
      "873,100.000,0.161\n",
      "874,100.000,0.178\n",
      "875,100.000,0.163\n",
      "876,100.000,0.164\n",
      "877,100.000,0.170\n",
      "878,100.000,0.166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "879,100.000,0.168\n",
      "880,100.000,0.152\n",
      "881,100.000,0.182\n",
      "882,100.000,0.163\n",
      "883,100.000,0.166\n",
      "884,100.000,0.169\n",
      "885,100.000,0.171\n",
      "886,100.000,0.156\n",
      "887,100.000,0.155\n",
      "888,100.000,0.156\n",
      "889,100.000,0.170\n",
      "890,100.000,0.168\n",
      "891,100.000,0.160\n",
      "892,100.000,0.154\n",
      "893,100.000,0.160\n",
      "894,100.000,0.172\n",
      "895,100.000,0.156\n",
      "896,100.000,0.143\n",
      "897,100.000,0.166\n",
      "898,100.000,0.180\n",
      "899,100.000,0.164\n",
      "900,100.000,0.165\n",
      "901,100.000,0.155\n",
      "902,100.000,0.160\n",
      "903,100.000,0.163\n",
      "904,100.000,0.172\n",
      "905,100.000,0.174\n",
      "906,100.000,0.151\n",
      "907,100.000,0.171\n",
      "908,100.000,0.159\n",
      "909,100.000,0.164\n",
      "910,100.000,0.170\n",
      "911,100.000,0.166\n",
      "912,100.000,0.152\n",
      "913,100.000,0.168\n",
      "914,100.000,0.174\n",
      "915,100.000,0.157\n",
      "916,100.000,0.165\n",
      "917,100.000,0.165\n",
      "918,100.000,0.163\n",
      "919,100.000,0.160\n",
      "920,100.000,0.164\n",
      "921,100.000,0.156\n",
      "922,100.000,0.168\n",
      "923,100.000,0.151\n",
      "924,100.000,0.149\n",
      "925,100.000,0.163\n",
      "926,100.000,0.158\n",
      "927,100.000,0.164\n",
      "928,100.000,0.152\n",
      "929,100.000,0.164\n",
      "930,100.000,0.162\n",
      "931,100.000,0.165\n",
      "932,100.000,0.163\n",
      "933,100.000,0.156\n",
      "934,100.000,0.185\n",
      "935,100.000,0.168\n",
      "936,100.000,0.153\n",
      "937,100.000,0.173\n",
      "938,100.000,0.160\n",
      "939,100.000,0.160\n",
      "940,100.000,0.162\n",
      "941,100.000,0.183\n",
      "942,100.000,0.153\n",
      "943,100.000,0.156\n",
      "944,100.000,0.157\n",
      "945,100.000,0.170\n",
      "946,100.000,0.167\n",
      "947,100.000,0.161\n",
      "948,100.000,0.156\n",
      "949,100.000,0.154\n",
      "950,100.000,0.183\n",
      "951,100.000,0.156\n",
      "952,100.000,0.178\n",
      "953,100.000,0.163\n",
      "954,100.000,0.152\n",
      "955,100.000,0.161\n",
      "956,100.000,0.181\n",
      "957,100.000,0.162\n",
      "958,100.000,0.165\n",
      "959,100.000,0.166\n",
      "960,100.000,0.154\n",
      "961,100.000,0.157\n",
      "962,100.000,0.182\n",
      "963,100.000,0.162\n",
      "964,100.000,0.165\n",
      "965,100.000,0.155\n",
      "966,100.000,0.173\n",
      "967,100.000,0.168\n",
      "968,100.000,0.167\n",
      "969,100.000,0.171\n",
      "970,100.000,0.162\n",
      "971,100.000,0.163\n",
      "972,100.000,0.151\n",
      "973,100.000,0.172\n",
      "974,100.000,0.183\n",
      "975,100.000,0.178\n",
      "976,100.000,0.172\n",
      "977,100.000,0.176\n",
      "978,100.000,0.179\n",
      "979,100.000,0.180\n",
      "980,100.000,0.166\n",
      "981,100.000,0.154\n",
      "982,100.000,0.174\n",
      "983,100.000,0.161\n",
      "984,100.000,0.153\n",
      "985,100.000,0.157\n",
      "986,100.000,0.172\n",
      "987,100.000,0.169\n",
      "988,100.000,0.191\n",
      "989,100.000,0.171\n",
      "990,100.000,0.172\n",
      "991,100.000,0.153\n",
      "992,100.000,0.183\n",
      "993,100.000,0.159\n",
      "994,100.000,0.177\n",
      "995,100.000,0.148\n",
      "996,100.000,0.165\n",
      "997,100.000,0.167\n",
      "998,100.000,0.150\n",
      "999,100.000,0.155\n",
      "SAVED..\n",
      "\n",
      "1001,100.000,0.189\n",
      "1002,100.000,0.167\n",
      "1003,100.000,0.168\n",
      "1004,100.000,0.153\n",
      "1005,100.000,0.171\n",
      "1006,100.000,0.153\n",
      "1007,100.000,0.158\n",
      "1008,100.000,0.162\n",
      "1009,100.000,0.160\n",
      "1010,100.000,0.166\n",
      "1011,100.000,0.165\n",
      "1012,100.000,0.166\n",
      "1013,100.000,0.170\n",
      "1014,100.000,0.163\n",
      "1015,100.000,0.163\n",
      "1016,100.000,0.166\n",
      "1017,100.000,0.167\n",
      "1018,100.000,0.163\n",
      "1019,100.000,0.177\n",
      "1020,100.000,0.153\n",
      "1021,100.000,0.164\n",
      "1022,100.000,0.183\n",
      "1023,100.000,0.155\n",
      "1024,100.000,0.174\n",
      "1025,100.000,0.158\n",
      "1026,100.000,0.150\n",
      "1027,100.000,0.157\n",
      "1028,100.000,0.184\n",
      "1029,100.000,0.169\n",
      "1030,100.000,0.174\n",
      "1031,99.219,0.164\n",
      "1032,100.000,0.163\n",
      "1033,100.000,0.169\n",
      "1034,100.000,0.154\n",
      "1035,100.000,0.152\n",
      "1036,100.000,0.155\n",
      "1037,100.000,0.163\n",
      "1038,100.000,0.163\n",
      "1039,100.000,0.164\n",
      "1040,100.000,0.186\n",
      "1041,100.000,0.158\n",
      "1042,100.000,0.162\n",
      "1043,100.000,0.189\n",
      "1044,100.000,0.189\n",
      "1045,100.000,0.158\n",
      "1046,100.000,0.161\n",
      "1047,100.000,0.168\n",
      "1048,100.000,0.160\n",
      "1049,100.000,0.178\n",
      "1050,100.000,0.173\n",
      "1051,100.000,0.167\n",
      "1052,100.000,0.191\n",
      "1053,100.000,0.197\n",
      "1054,100.000,0.148\n",
      "1055,100.000,0.164\n",
      "1056,100.000,0.156\n",
      "1057,100.000,0.171\n",
      "1058,100.000,0.163\n",
      "1059,100.000,0.162\n",
      "1060,100.000,0.160\n",
      "1061,100.000,0.170\n",
      "1062,100.000,0.151\n",
      "1063,100.000,0.160\n",
      "1064,100.000,0.169\n",
      "1065,100.000,0.169\n",
      "1066,100.000,0.177\n",
      "1067,100.000,0.165\n",
      "1068,100.000,0.177\n",
      "1069,100.000,0.167\n",
      "1070,100.000,0.181\n",
      "1071,100.000,0.155\n",
      "1072,100.000,0.172\n",
      "1073,100.000,0.167\n",
      "1074,100.000,0.157\n",
      "1075,100.000,0.165\n",
      "1076,100.000,0.155\n",
      "1077,100.000,0.163\n",
      "1078,100.000,0.174\n",
      "1079,100.000,0.153\n",
      "1080,100.000,0.168\n",
      "1081,100.000,0.152\n",
      "1082,100.000,0.186\n",
      "1083,100.000,0.168\n",
      "1084,100.000,0.180\n",
      "1085,100.000,0.181\n",
      "1086,100.000,0.164\n",
      "1087,100.000,0.161\n",
      "1088,100.000,0.161\n",
      "1089,100.000,0.183\n",
      "1090,100.000,0.182\n",
      "1091,100.000,0.171\n",
      "1092,100.000,0.171\n",
      "1093,100.000,0.159\n",
      "1094,100.000,0.166\n",
      "1095,100.000,0.166\n",
      "1096,100.000,0.173\n",
      "1097,100.000,0.175\n",
      "1098,100.000,0.177\n",
      "1099,100.000,0.159\n",
      "1100,100.000,0.170\n",
      "1101,100.000,0.163\n",
      "1102,100.000,0.155\n",
      "1103,100.000,0.170\n",
      "1104,100.000,0.169\n",
      "1105,100.000,0.175\n",
      "1106,100.000,0.161\n",
      "1107,100.000,0.184\n",
      "1108,100.000,0.166\n",
      "1109,100.000,0.171\n",
      "1110,100.000,0.153\n",
      "1111,100.000,0.168\n",
      "1112,100.000,0.160\n",
      "1113,100.000,0.171\n",
      "1114,100.000,0.155\n",
      "1115,100.000,0.168\n",
      "1116,100.000,0.151\n",
      "1117,100.000,0.168\n",
      "1118,100.000,0.156\n",
      "1119,100.000,0.177\n",
      "1120,100.000,0.160\n",
      "1121,100.000,0.164\n",
      "1122,100.000,0.158\n",
      "1123,100.000,0.156\n",
      "1124,100.000,0.174\n",
      "1125,100.000,0.169\n",
      "1126,100.000,0.159\n",
      "1127,100.000,0.173\n",
      "1128,100.000,0.149\n",
      "1129,100.000,0.164\n",
      "1130,100.000,0.175\n",
      "1131,100.000,0.162\n",
      "1132,100.000,0.170\n",
      "1133,100.000,0.164\n",
      "1134,100.000,0.163\n",
      "1135,100.000,0.178\n",
      "1136,100.000,0.177\n",
      "1137,100.000,0.170\n",
      "1138,100.000,0.171\n",
      "1139,100.000,0.156\n",
      "1140,100.000,0.155\n",
      "1141,100.000,0.156\n",
      "1142,100.000,0.156\n",
      "1143,100.000,0.171\n",
      "1144,100.000,0.151\n",
      "1145,100.000,0.179\n",
      "1146,100.000,0.168\n",
      "1147,100.000,0.171\n",
      "1148,100.000,0.162\n",
      "1149,100.000,0.155\n",
      "1150,100.000,0.166\n",
      "1151,100.000,0.189\n",
      "1152,100.000,0.168\n",
      "1153,100.000,0.179\n",
      "1154,100.000,0.167\n",
      "1155,100.000,0.162\n",
      "1156,100.000,0.166\n",
      "1157,100.000,0.179\n",
      "1158,100.000,0.168\n",
      "1159,100.000,0.169\n",
      "1160,100.000,0.169\n",
      "1161,100.000,0.165\n",
      "1162,100.000,0.158\n",
      "1163,100.000,0.171\n",
      "1164,100.000,0.150\n",
      "1165,100.000,0.162\n",
      "1166,100.000,0.163\n",
      "1167,100.000,0.169\n",
      "1168,100.000,0.170\n",
      "1169,100.000,0.163\n",
      "1170,100.000,0.146\n",
      "1171,100.000,0.168\n",
      "1172,100.000,0.160\n",
      "1173,100.000,0.166\n",
      "1174,100.000,0.171\n",
      "1175,100.000,0.163\n",
      "1176,100.000,0.168\n",
      "1177,100.000,0.174\n",
      "1178,100.000,0.166\n",
      "1179,100.000,0.164\n",
      "1180,100.000,0.154\n",
      "1181,100.000,0.172\n",
      "1182,100.000,0.162\n",
      "1183,100.000,0.161\n",
      "1184,100.000,0.158\n",
      "1185,100.000,0.159\n",
      "1186,100.000,0.173\n",
      "1187,100.000,0.161\n",
      "1188,100.000,0.178\n",
      "1189,100.000,0.174\n",
      "1190,100.000,0.181\n",
      "1191,100.000,0.161\n",
      "1192,100.000,0.164\n",
      "1193,100.000,0.173\n",
      "1194,100.000,0.158\n",
      "1195,100.000,0.161\n",
      "1196,100.000,0.160\n",
      "1197,100.000,0.154\n",
      "1198,100.000,0.158\n",
      "1199,100.000,0.161\n",
      "1200,100.000,0.173\n",
      "1201,100.000,0.173\n",
      "1202,100.000,0.179\n",
      "1203,100.000,0.162\n",
      "1204,100.000,0.163\n",
      "1205,100.000,0.148\n",
      "1206,100.000,0.159\n",
      "1207,100.000,0.173\n",
      "1208,100.000,0.174\n",
      "1209,100.000,0.153\n",
      "1210,100.000,0.164\n",
      "1211,100.000,0.163\n",
      "1212,100.000,0.156\n",
      "1213,100.000,0.163\n",
      "1214,100.000,0.147\n",
      "1215,100.000,0.180\n",
      "1216,100.000,0.166\n",
      "1217,100.000,0.176\n",
      "1218,100.000,0.178\n",
      "1219,100.000,0.177\n",
      "1220,100.000,0.170\n",
      "1221,100.000,0.183\n",
      "1222,100.000,0.169\n",
      "1223,100.000,0.170\n",
      "1224,100.000,0.165\n",
      "1225,100.000,0.175\n",
      "1226,100.000,0.149\n",
      "1227,100.000,0.171\n",
      "1228,100.000,0.178\n",
      "1229,100.000,0.168\n",
      "1230,100.000,0.150\n",
      "1231,100.000,0.172\n",
      "1232,100.000,0.178\n",
      "1233,100.000,0.168\n",
      "1234,100.000,0.168\n",
      "1235,100.000,0.171\n",
      "1236,100.000,0.181\n",
      "1237,100.000,0.149\n",
      "1238,100.000,0.164\n",
      "1239,100.000,0.163\n",
      "1240,100.000,0.155\n",
      "1241,100.000,0.168\n",
      "1242,100.000,0.164\n",
      "1243,100.000,0.173\n",
      "1244,100.000,0.161\n",
      "1245,100.000,0.179\n",
      "1246,100.000,0.164\n",
      "1247,100.000,0.165\n",
      "1248,100.000,0.164\n",
      "1249,100.000,0.155\n",
      "1250,100.000,0.164\n",
      "1251,100.000,0.175\n",
      "1252,100.000,0.181\n",
      "1253,100.000,0.157\n",
      "1254,100.000,0.163\n",
      "1255,100.000,0.184\n",
      "1256,100.000,0.180\n",
      "1257,100.000,0.201\n",
      "1258,100.000,0.177\n",
      "1259,100.000,0.179\n",
      "1260,100.000,0.172\n",
      "1261,100.000,0.153\n",
      "1262,100.000,0.163\n",
      "1263,100.000,0.168\n",
      "1264,100.000,0.169\n",
      "1265,100.000,0.177\n",
      "1266,100.000,0.174\n",
      "1267,100.000,0.175\n",
      "1268,100.000,0.160\n",
      "1269,100.000,0.158\n",
      "1270,100.000,0.169\n",
      "1271,100.000,0.156\n",
      "1272,100.000,0.161\n",
      "1273,100.000,0.161\n",
      "1274,100.000,0.153\n",
      "1275,100.000,0.158\n",
      "1276,100.000,0.168\n",
      "1277,100.000,0.175\n",
      "1278,100.000,0.152\n",
      "1279,100.000,0.155\n",
      "1280,100.000,0.158\n",
      "1281,100.000,0.164\n",
      "1282,100.000,0.172\n",
      "1283,100.000,0.167\n",
      "1284,100.000,0.168\n",
      "1285,100.000,0.170\n",
      "1286,100.000,0.163\n",
      "1287,100.000,0.176\n",
      "1288,100.000,0.178\n",
      "1289,100.000,0.165\n",
      "1290,100.000,0.169\n",
      "1291,100.000,0.172\n",
      "1292,100.000,0.150\n",
      "1293,100.000,0.165\n",
      "1294,100.000,0.179\n",
      "1295,100.000,0.177\n",
      "1296,100.000,0.161\n",
      "1297,100.000,0.154\n",
      "1298,100.000,0.172\n",
      "1299,100.000,0.165\n",
      "1300,100.000,0.165\n",
      "1301,100.000,0.152\n",
      "1302,100.000,0.179\n",
      "1303,100.000,0.172\n",
      "1304,100.000,0.162\n",
      "1305,100.000,0.171\n",
      "1306,100.000,0.166\n",
      "1307,100.000,0.173\n",
      "1308,100.000,0.177\n",
      "1309,100.000,0.171\n",
      "1310,100.000,0.163\n",
      "1311,100.000,0.154\n",
      "1312,100.000,0.151\n",
      "1313,100.000,0.188\n",
      "1314,100.000,0.157\n",
      "1315,100.000,0.169\n",
      "1316,100.000,0.180\n",
      "1317,100.000,0.178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1318,100.000,0.163\n",
      "1319,100.000,0.168\n",
      "1320,100.000,0.168\n",
      "1321,100.000,0.173\n",
      "1322,100.000,0.170\n",
      "1323,100.000,0.168\n",
      "1324,99.219,0.146\n",
      "1325,100.000,0.163\n",
      "1326,100.000,0.173\n",
      "1327,100.000,0.164\n",
      "1328,100.000,0.187\n",
      "1329,100.000,0.147\n",
      "1330,100.000,0.146\n",
      "1331,100.000,0.166\n",
      "1332,100.000,0.170\n",
      "1333,100.000,0.164\n",
      "1334,100.000,0.160\n",
      "1335,100.000,0.157\n",
      "1336,100.000,0.169\n",
      "1337,100.000,0.150\n",
      "1338,100.000,0.166\n",
      "1339,100.000,0.164\n",
      "1340,100.000,0.174\n",
      "1341,100.000,0.175\n",
      "1342,100.000,0.171\n",
      "1343,100.000,0.172\n",
      "1344,100.000,0.176\n",
      "1345,100.000,0.143\n",
      "1346,100.000,0.165\n",
      "1347,100.000,0.158\n",
      "1348,100.000,0.156\n",
      "1349,100.000,0.146\n",
      "1350,100.000,0.175\n",
      "1351,100.000,0.168\n",
      "1352,100.000,0.173\n",
      "1353,100.000,0.161\n",
      "1354,100.000,0.163\n",
      "1355,100.000,0.163\n",
      "1356,100.000,0.158\n",
      "1357,100.000,0.173\n",
      "1358,100.000,0.160\n",
      "1359,100.000,0.165\n",
      "1360,100.000,0.163\n",
      "1361,100.000,0.174\n",
      "1362,100.000,0.169\n",
      "1363,100.000,0.158\n",
      "1364,100.000,0.169\n",
      "1365,100.000,0.146\n",
      "1366,100.000,0.172\n",
      "1367,100.000,0.162\n",
      "1368,100.000,0.159\n",
      "1369,100.000,0.172\n",
      "1370,100.000,0.160\n",
      "1371,100.000,0.172\n",
      "1372,100.000,0.168\n",
      "1373,100.000,0.168\n",
      "1374,100.000,0.156\n",
      "1375,100.000,0.157\n",
      "1376,100.000,0.165\n",
      "1377,100.000,0.153\n",
      "1378,100.000,0.171\n",
      "1379,100.000,0.162\n",
      "1380,100.000,0.163\n",
      "1381,100.000,0.169\n",
      "1382,100.000,0.183\n",
      "1383,100.000,0.173\n",
      "1384,100.000,0.178\n",
      "1385,100.000,0.153\n",
      "1386,100.000,0.156\n",
      "1387,100.000,0.159\n",
      "1388,100.000,0.162\n",
      "1389,100.000,0.184\n",
      "1390,100.000,0.156\n",
      "1391,100.000,0.166\n",
      "1392,100.000,0.172\n",
      "1393,100.000,0.169\n",
      "1394,100.000,0.170\n",
      "1395,100.000,0.168\n",
      "1396,100.000,0.164\n",
      "1397,100.000,0.166\n",
      "1398,100.000,0.164\n",
      "1399,100.000,0.171\n",
      "1400,100.000,0.167\n",
      "1401,100.000,0.172\n",
      "1402,100.000,0.164\n",
      "1403,100.000,0.152\n",
      "1404,100.000,0.178\n",
      "1405,100.000,0.166\n",
      "1406,100.000,0.170\n",
      "1407,100.000,0.174\n",
      "1408,100.000,0.156\n",
      "1409,100.000,0.176\n",
      "1410,100.000,0.167\n",
      "1411,100.000,0.167\n",
      "1412,100.000,0.150\n",
      "1413,100.000,0.170\n",
      "1414,100.000,0.162\n",
      "1415,100.000,0.190\n",
      "1416,100.000,0.157\n",
      "1417,100.000,0.167\n",
      "1418,100.000,0.162\n",
      "1419,100.000,0.168\n",
      "1420,100.000,0.177\n",
      "1421,100.000,0.160\n",
      "1422,100.000,0.173\n",
      "1423,100.000,0.165\n",
      "1424,100.000,0.152\n",
      "1425,100.000,0.156\n",
      "1426,100.000,0.155\n",
      "1427,100.000,0.185\n",
      "1428,100.000,0.147\n",
      "1429,100.000,0.173\n",
      "1430,100.000,0.151\n",
      "1431,100.000,0.171\n",
      "1432,100.000,0.160\n",
      "1433,100.000,0.181\n",
      "1434,100.000,0.168\n",
      "1435,100.000,0.163\n",
      "1436,100.000,0.157\n",
      "1437,100.000,0.168\n",
      "1438,100.000,0.157\n",
      "1439,100.000,0.161\n",
      "1440,100.000,0.182\n",
      "1441,100.000,0.158\n",
      "1442,100.000,0.165\n",
      "1443,100.000,0.166\n",
      "1444,100.000,0.168\n",
      "1445,100.000,0.151\n",
      "1446,100.000,0.158\n",
      "1447,100.000,0.167\n",
      "1448,100.000,0.174\n",
      "1449,100.000,0.165\n",
      "1450,100.000,0.169\n",
      "1451,100.000,0.167\n",
      "1452,100.000,0.153\n",
      "1453,100.000,0.183\n",
      "1454,100.000,0.164\n",
      "1455,100.000,0.186\n",
      "1456,100.000,0.155\n",
      "1457,100.000,0.175\n",
      "1458,100.000,0.174\n",
      "1459,100.000,0.154\n",
      "1460,100.000,0.164\n",
      "1461,100.000,0.156\n",
      "1462,100.000,0.169\n",
      "1463,100.000,0.161\n",
      "1464,100.000,0.170\n",
      "1465,100.000,0.156\n",
      "1466,100.000,0.165\n",
      "1467,100.000,0.171\n",
      "1468,100.000,0.164\n",
      "1469,100.000,0.176\n",
      "1470,100.000,0.184\n",
      "1471,100.000,0.171\n",
      "1472,100.000,0.167\n",
      "1473,100.000,0.144\n",
      "1474,100.000,0.159\n",
      "1475,100.000,0.172\n",
      "1476,100.000,0.154\n",
      "1477,100.000,0.166\n",
      "1478,100.000,0.157\n",
      "1479,100.000,0.149\n",
      "1480,100.000,0.154\n",
      "1481,100.000,0.164\n",
      "1482,100.000,0.165\n",
      "1483,100.000,0.175\n",
      "1484,100.000,0.164\n",
      "1485,100.000,0.163\n",
      "1486,100.000,0.175\n",
      "1487,100.000,0.169\n",
      "1488,100.000,0.170\n",
      "1489,100.000,0.160\n",
      "1490,100.000,0.162\n",
      "1491,100.000,0.158\n",
      "1492,100.000,0.179\n",
      "1493,100.000,0.187\n",
      "1494,100.000,0.170\n",
      "1495,100.000,0.173\n",
      "1496,100.000,0.175\n",
      "1497,100.000,0.171\n",
      "1498,100.000,0.169\n",
      "1499,100.000,0.174\n",
      "SAVED..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Training:\n",
    "\"\"\"\n",
    "55,000 data points of training data (mnist.train),\n",
    "10,000 points of test data (mnist.test)\n",
    "and 5,000 points of validation data (mnist.validation).\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "\n",
    "caps_net = CapsNet(lr=lr)\n",
    "print('Network Built..')\n",
    "\n",
    "tvars = tf.trainable_variables()\n",
    "saver = tf.train.Saver(var_list=tvars)\n",
    "\n",
    "file = open('avg_log_{}.csv'.format(train_round), 'w') # avg. acc over last 500 train steps, validation acc to file.\n",
    "file.write('step,avg_train_acc,step_val_acc\\n')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    if resume:\n",
    "        saver.restore(sess, ckpt)\n",
    "        print(\"RESUMED..\")\n",
    "    \n",
    "    if do_test_first:\n",
    "        test_batch_size = 250\n",
    "        ta = 0\n",
    "        total_steps = len(mnist.test.images)//test_batch_size\n",
    "        for step in range(1, total_steps+1):\n",
    "            val_x, val_y = mnist.test.next_batch(test_batch_size)\n",
    "            test_batch_accuracy = caps_net.learn(None, \n",
    "                                                 None, \n",
    "                                                 val_xs=val_x,\n",
    "                                                 val_ys=val_y,\n",
    "                                                 sess=sess)\n",
    "            ta += test_batch_accuracy\n",
    "            print('{},{:>3.3f}'.format(step, test_batch_accuracy))\n",
    "    \n",
    "    print('Test Accuracy: ', ta / total_steps)\n",
    "    print('*'*90)\n",
    "    print('Training..learning_rate = {}, total_epochs = {}'.format(lr, epoch))\n",
    "    total_steps_approx = 500 * epoch\n",
    "    ta = 0\n",
    "    for step in range(1, total_steps_approx + 1):\n",
    "\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size, shuffle=True)\n",
    "        global_step = sess.run(caps_net.global_step)\n",
    "\n",
    "        if step % save_after == 0:\n",
    "            saver.save(sess, ckpt)\n",
    "            print(\"SAVED..\")\n",
    "\n",
    "            va = 0\n",
    "            for v in range(200):\n",
    "                val_x, val_y = mnist.validation.next_batch(250, shuffle=True)\n",
    "                val_accuracy = caps_net.learn(None, \n",
    "                                              None, \n",
    "                                              val_xs=val_x,\n",
    "                                              val_ys=val_y,\n",
    "                                              sess=sess)\n",
    "                va += val_accuracy\n",
    "\n",
    "            print()\n",
    "            file.write('{},{:>3.3f},{:>3.3f}\\n'.format(step, ta / 500, va / 200))\n",
    "            file.flush()\n",
    "            ta = 0\n",
    "\n",
    "        else:\n",
    "            train_accuracy, train_loss = caps_net.learn(batch_x, batch_y, sess=sess)\n",
    "            print('{},{:>3.3f},{:>3.3f}'.format(step, train_accuracy, train_loss))\n",
    "            ta += train_accuracy\n",
    "\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
